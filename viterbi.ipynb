{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95cf98e4-5d43-43a1-bfa3-c457aa2a6aa0",
   "metadata": {},
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aecfb9f5-5a61-4e69-a063-fb9d6fc6c216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddir = '/Users/lohyikuang/Downloads/school_semesters/2024 Y3 SEMESTER 2/BT 3102/final_project/project_files' \n",
    "\n",
    "in_train_filename = f'{ddir}/twitter_train.txt' # Training file\n",
    "naive_output_probs_filename = f'{ddir}/naive_output_probs.txt' # Output file\n",
    "in_test_filename = f'{ddir}/twitter_dev_no_tag.txt' # Does not contain tag\n",
    "in_ans_filename  = f'{ddir}/twitter_dev_ans.txt' # Does not contain tokens\n",
    "tags_filename = f'{ddir}/twitter_tags.txt' # 25 Tags\n",
    "naive_prediction_filename = f'{ddir}/naive_predictions.txt'\n",
    "\n",
    "def evaluate(in_prediction_filename, in_answer_filename):\n",
    "    \"\"\"Do not change this method\"\"\"\n",
    "    with open(in_prediction_filename) as fin:\n",
    "        predicted_tags = [l.strip() for l in fin.readlines() if len(l.strip()) != 0]\n",
    "\n",
    "    with open(in_answer_filename) as fin:\n",
    "        ground_truth_tags = [l.strip() for l in fin.readlines() if len(l.strip()) != 0]\n",
    "\n",
    "    assert len(predicted_tags) == len(ground_truth_tags)\n",
    "    correct = 0\n",
    "    for pred, truth in zip(predicted_tags, ground_truth_tags):\n",
    "        if pred == truth: correct += 1\n",
    "    return correct, len(predicted_tags), correct/len(predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a8d7af-9226-4c30-aeb6-329d1443826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Tags: [@, ,, L, ~, &, S, N, A, G, $, V, R, X, E, T, M, D, O, Z, !, ^, U, P, Y, #]\n"
     ]
    }
   ],
   "source": [
    "with open(tags_filename, \"r\") as f:\n",
    "    possible_tags = [line.strip() for line in f]\n",
    "print(f\"Possible Tags: [{', '.join(possible_tags)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b99a1c-7032-4cfd-a22b-555424be7bc8",
   "metadata": {},
   "source": [
    "### 2.1 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a739c981-ee6f-4159-985b-6461fe4ac033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def maximum_likelihood_estimate(\n",
    "    delta: float,\n",
    "    in_train_filename: str,\n",
    "    in_output_probs_filename: str\n",
    "):\n",
    "    tag_counter = defaultdict(lambda: defaultdict(int))\n",
    "    tag_counts, word_counts = defaultdict(int), defaultdict(int)\n",
    "    \n",
    "    with open(in_train_filename, \"r\") as f:\n",
    "        for line in f: \n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) == 2:\n",
    "                word, tag = parts\n",
    "                tag_counter[tag][word] += 1\n",
    "                tag_counts[tag] += 1\n",
    "                word_counts[word] += 1\n",
    "                \n",
    "    n_unique_words: int = len(word_counts)\n",
    "    \n",
    "    # observed data x1, x2, ..., xn  \n",
    "    # associated tags y1, y2, ..., yn \n",
    "    with open(in_output_probs_filename, \"w\") as f:\n",
    "        for tag in tag_counter:\n",
    "            for word in tag_counter[tag]:\n",
    "                smoothed_prob = (tag_counter[tag][word] + delta) / (tag_counts[tag] + delta * (n_unique_words + 1))\n",
    "                f.write(f\"{tag} \\t {word} \\t {smoothed_prob}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e754b2d5-e641-4d51-92f1-cf6f584ee95d",
   "metadata": {},
   "source": [
    "### 2.1 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4ec116-c362-451f-b6f4-ed11a85e41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_predict(\n",
    "    in_output_probs_filename, \n",
    "    in_test_filename, \n",
    "    out_prediction_filename\n",
    "):\n",
    "    probs = defaultdict(dict)\n",
    "    with open(in_output_probs_filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            tag, word, prob = line.strip().split()\n",
    "            probs[word][tag] = float(prob)\n",
    "    \n",
    "    with open(in_test_filename, \"r\") as test_f, open(out_prediction_filename, 'w') as pred_f:\n",
    "        for line in test_f:\n",
    "            word = line.strip()\n",
    "            if word: \n",
    "                best_tag, best_prob = max(\n",
    "                    probs.get(word, {}).items(), \n",
    "                    key=lambda x: x[1], \n",
    "                    default=(\"@\", 0)\n",
    "                )\n",
    "                pred_f.write(f\"{best_tag}\\n\")\n",
    "            else:\n",
    "                pred_f.write(\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f3f4a84-5a11-4386-b2a2-0a7bfb575b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [00:30<00:00, 32.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "npo_probs = {}\n",
    "\n",
    "# Perform grid search\n",
    "for delta in tqdm(range(1, 1000)):\n",
    "    delta /= 100\n",
    "    maximum_likelihood_estimate(delta, in_train_filename, naive_output_probs_filename)\n",
    "    naive_predict(naive_output_probs_filename, in_test_filename, naive_prediction_filename)\n",
    "    correct, total, acc = evaluate(naive_prediction_filename, in_ans_filename)\n",
    "    npo_probs[delta] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a64fc2-e17e-42b4-80b1-f579349bbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter search to find the best Delta \n",
    "maximum_likelihood_estimate(\n",
    "    0.34, \n",
    "    in_train_filename, \n",
    "    naive_output_probs_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97c016a-5106-4e37-9714-03948a048786",
   "metadata": {},
   "source": [
    "### 2.1 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b46f32-da13-4a0a-8191-d0beaedd5109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(967, 1378, 0.7017416545718432)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct, total, acc = evaluate(naive_prediction_filename, in_ans_filename)\n",
    "correct, total, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c026b-d13d-467a-8293-6219f5bf3106",
   "metadata": {},
   "source": [
    "### 2.2 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ef59db2-a097-468e-8fc6-72103e31955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_predict2(\n",
    "    in_output_probs_filename, \n",
    "    in_train_filename, \n",
    "    in_test_filename, \n",
    "    out_prediction_filename\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6410715-4ac6-422d-8987-deb1abe0720e",
   "metadata": {},
   "source": [
    "### 3 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a701d3f-f91b-4960-b257-2e888b1922e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_probs_filename =  f'{ddir}/trans_probs.txt'\n",
    "output_probs_filename = f'{ddir}/output_probs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "052f33ea-72bf-4dca-96e7-52581d8dcdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_likelihood_viterbi(\n",
    "    in_train_filename,\n",
    "    trans_probs_filename,\n",
    "    output_probs_filename,\n",
    "):\n",
    "    # Our hidden states are the N,V,A etc\n",
    "    # Our emission or observed states are the words themselves\n",
    "    tag_transition = defaultdict(lambda: defaultdict(int))\n",
    "    tag_emission = defaultdict(lambda: defaultdict(int))\n",
    "    tag_counter = defaultdict(int)\n",
    "    i = 'START' # Front tag. This will get us from start state to some other state\n",
    "    \n",
    "    with open(in_train_filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 0:\n",
    "                tag_transition[i]['END'] += 1  # Transition to 'END' state\n",
    "                i = 'START'  # Reset for the next sentence\n",
    "                continue\n",
    "            w, j = parts\n",
    "            w = w.lower() # Some words like Today, today are counted as different\n",
    "            if i == 'START':\n",
    "                tag_counter[i] += 1  # Count 'START' transitions\n",
    "            tag_emission[j][w] += 1  # hidden -> observed\n",
    "            tag_transition[i][j] += 1  # hidden -> hidden\n",
    "            tag_counter[j] += 1\n",
    "            i = j\n",
    "\n",
    "    # Add transition from the last tag to 'END' for the last sentence\n",
    "    tag_transition[i]['END'] += 1\n",
    "    tag_counter['END'] += 1\n",
    "\n",
    "    with open(trans_probs_filename, 'w') as f:\n",
    "        for i in tag_transition:\n",
    "            for j in tag_transition[i]:\n",
    "                trans_prob_val = tag_transition[i][j] / tag_counter[j]\n",
    "                f.write(f\"{i} \\t {j} \\t {trans_prob_val}\\n\")\n",
    "    \n",
    "    with open(output_probs_filename, \"w\") as f:\n",
    "        for j in tag_emission: \n",
    "            for w in tag_emission[j]:\n",
    "                emission_prob_val = tag_emission[j][w] / tag_counter[j]\n",
    "                f.write(f\"{j} \\t {w} \\t {emission_prob_val}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "57f7fc04-6acd-4925-90a0-b4cbc2cd57e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_likelihood_viterbi(\n",
    "    in_train_filename,\n",
    "    trans_probs_filename,\n",
    "    output_probs_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ce6d23-a547-47d0-a846-ea0afc50c719",
   "metadata": {},
   "source": [
    "### 3 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "05923319-9338-4b23-b157-04b38ca03ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_tags_filename = f'{ddir}/twitter_tags.txt'\n",
    "viterbi_predictions_filename = f'{ddir}/viterbi_predictions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1ecd2ee7-2497-42f0-87d4-885e7c4257c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def viterbi_predict(\n",
    "    in_tags_filename, # Contains the full set of tags \n",
    "    in_trans_probs_filename, # Transition probabilties\n",
    "    in_output_probs_filename, # Emission probabilities\n",
    "    in_test_filename, # The input file containing some word tags\n",
    "    out_predictions_filename # Output predictions\n",
    "):\n",
    "    # Preload all the information we need\n",
    "    with open(in_tags_filename, \"r\") as f:\n",
    "        states = [tag.strip() for tag in f]\n",
    "\n",
    "    transition_probabilties = {}\n",
    "    with open(in_trans_probs_filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            prev_tag, next_tag, prob = line.strip().split(\"\\t\")\n",
    "            prev_tag, next_tag = prev_tag.strip(), next_tag.strip()\n",
    "            if prev_tag not in transition_probabilties:\n",
    "                transition_probabilties[prev_tag] = {}\n",
    "            transition_probabilties[prev_tag][next_tag] = float(prob)\n",
    "\n",
    "    output_probabilities = {}\n",
    "    with open(in_output_probs_filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            word, tag, prob = line.strip().split(\"\\t\")\n",
    "            word, tag = word.strip(), tag.strip()\n",
    "            if word not in output_probabilities: \n",
    "                output_probabilities[word] = {}\n",
    "            output_probabilities[word][tag] = float(prob)\n",
    "    \n",
    "    with open(in_test_filename, \"r\") as f:\n",
    "        posts, post = [], []\n",
    "        for word in f: \n",
    "            word = word.strip().lower()\n",
    "            if word == \"\": \n",
    "                posts.append(post)\n",
    "                post = []\n",
    "                continue\n",
    "            post.append(word)\n",
    "    \n",
    "    def mask_get(d, key1, key2):\n",
    "        # Mask for the tokens not observed in the training set\n",
    "        return d.get(key1, {}).get(key2, 1e-10)\n",
    "    \n",
    "    def single_post_viterbi(\n",
    "        obs, \n",
    "        states, \n",
    "        trans_p, \n",
    "        emit_p\n",
    "    ):\n",
    "        V, path = [{}], {}  \n",
    "        for state in states: \n",
    "            V[0][state] = mask_get(trans_p, 'START', state) * mask_get(emit_p, state, obs[0])\n",
    "            path[state] = [state] \n",
    "        \n",
    "        for t in range(1, len(obs)): \n",
    "            V.append({})\n",
    "            newpath = {}\n",
    "            \n",
    "            for cur_state in states: \n",
    "                step_score = []\n",
    "                for prev_state in states:\n",
    "                    score = (\n",
    "                        V[t - 1][prev_state] * \n",
    "                        mask_get(trans_p, prev_state, cur_state) * \n",
    "                        mask_get(emit_p, cur_state, obs[t])\n",
    "                    )\n",
    "                    step_score.append((score, prev_state))\n",
    "                max_score, max_state = max(step_score)\n",
    "                V[t][cur_state] = max_score\n",
    "                newpath[cur_state] = path[max_state] + [cur_state]\n",
    "            path = newpath\n",
    "            \n",
    "        (prob, state) = max((V[len(obs) - 1][y], y) for y in states)\n",
    "        return (prob, path[state])\n",
    "    \n",
    "    with open(out_predictions_filename, \"w\") as f:\n",
    "        for post in posts: \n",
    "            prob, paths = single_post_viterbi(post, states, transition_probabilties, output_probabilities)\n",
    "            for state in paths:\n",
    "                f.write(f\"{state}\\n\")  \n",
    "            f.write(f\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6a5b65b0-66f7-4229-ad8e-31b4e7e6c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi_predict(\n",
    "    in_tags_filename, \n",
    "    trans_probs_filename, \n",
    "    output_probs_filename, \n",
    "    in_test_filename, \n",
    "    viterbi_predictions_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfeb081-5cf2-4c6f-87d2-821b093578af",
   "metadata": {},
   "source": [
    "### 3 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4a6a8cb-3c5f-4a7c-98b1-9723795b2fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072, 1378, 0.7779390420899854)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    viterbi_predictions_filename, \n",
    "    in_ans_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b11dc-3908-4f54-94a9-80580f362458",
   "metadata": {},
   "source": [
    "### 4 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "63da9a87-6944-45a8-b8d0-d825f5925a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(viterbi_predictions_filename, \"r\") as f, open(in_ans_filename, \"r\") as fa:\n",
    "    preds = [line.strip(\"\\n\") for line in f]\n",
    "    ans = [line.strip(\"\\n\") for line in fa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fa81736a-a415-4f0a-8fd6-cd685fbd748e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>,</td>\n",
       "      <td>^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>V</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>!</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>,</td>\n",
       "      <td>^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>N</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>Y</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>V</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preds ans\n",
       "3        V   A\n",
       "40       ,   ^\n",
       "42       V   $\n",
       "43       T   N\n",
       "46       !   D\n",
       "...    ...  ..\n",
       "1433     P   A\n",
       "1445     ,   ^\n",
       "1447     N   !\n",
       "1449     Y   !\n",
       "1455     V   A\n",
       "\n",
       "[243 rows x 2 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([preds, ans]).T\n",
    "df.columns = ['preds', 'ans']\n",
    "df[(df.preds != df.ans) & (df.preds.str.strip() != '')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7cb421-8f3a-44c0-a101-adf22e331cae",
   "metadata": {},
   "source": [
    "### 4 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4b500137-7ed5-45c4-a9d7-d41efa123d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_probs_filename2 =  f'{ddir}/trans_probs2.txt'\n",
    "output_probs_filename2 = f'{ddir}/output_probs2.txt'\n",
    "\n",
    "viterbi_predictions_filename2 = f'{ddir}/viterbi_predictions2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4b50b466-97a1-4b22-a36e-d937ef339d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_likelihood_viterbi(\n",
    "    in_train_filename,\n",
    "    trans_probs_filename2,\n",
    "    output_probs_filename2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1b07e83-80ca-4e8a-bd85-1cf727c1010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "with open(in_train_filename, \"r\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 0:\n",
    "            continue\n",
    "        word, tag = parts\n",
    "        if word not in d: \n",
    "            d[word] = {}\n",
    "        if tag not in d[word]:\n",
    "            d[word][tag] = 0\n",
    "        d[word][tag] += 1\n",
    "        \n",
    "filtered_d = {}\n",
    "for word, tags in d.items():\n",
    "    # We will directly tag the words if the word is only ever tagged with 1\n",
    "    if len(tags) == 1:\n",
    "        for k, v in tags.items():\n",
    "            filtered_d[word] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4b87c1af-02fd-450b-ade6-1a45f9cef45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_predict2(\n",
    "    in_tags_filename, # Contains the full set of tags \n",
    "    in_trans_probs_filename, # Transition probabilties\n",
    "    in_output_probs_filename, # Emission probabilities\n",
    "    in_test_filename, # The input file containing some word tags\n",
    "    out_predictions_filename # Output predictions\n",
    "):\n",
    "    # Preload all the information we need\n",
    "    with open(in_tags_filename, \"r\") as f:\n",
    "        states = [tag.strip() for tag in f]\n",
    "\n",
    "    transition_probabilties = {}\n",
    "    with open(in_trans_probs_filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            prev_tag, next_tag, prob = line.strip().split(\"\\t\")\n",
    "            prev_tag, next_tag = prev_tag.strip(), next_tag.strip()\n",
    "            if prev_tag not in transition_probabilties:\n",
    "                transition_probabilties[prev_tag] = {}\n",
    "            transition_probabilties[prev_tag][next_tag] = float(prob)\n",
    "\n",
    "    output_probabilities = {}\n",
    "    with open(in_output_probs_filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            word, tag, prob = line.strip().split(\"\\t\")\n",
    "            word, tag = word.strip(), tag.strip()\n",
    "            if word not in output_probabilities: \n",
    "                output_probabilities[word] = {}\n",
    "            output_probabilities[word][tag] = float(prob)\n",
    "    \n",
    "    with open(in_test_filename, \"r\") as f:\n",
    "        posts, post = [], []\n",
    "        for word in f: \n",
    "            word = word.strip().lower()\n",
    "            if word == \"\": \n",
    "                posts.append(post)\n",
    "                post = []\n",
    "                continue\n",
    "            post.append(word)\n",
    "    \n",
    "    def mask_get(d, key1, key2):\n",
    "        # Mask for the tokens not observed in the training set\n",
    "        return d.get(key1, {}).get(key2, 1e-10)\n",
    "    \n",
    "    def single_post_viterbi(\n",
    "        obs, \n",
    "        states, \n",
    "        trans_p, \n",
    "        emit_p\n",
    "    ):\n",
    "        V, path = [{}], {}  \n",
    "        for state in states: \n",
    "            V[0][state] = mask_get(trans_p, 'START', state) * mask_get(emit_p, state, obs[0])\n",
    "            path[state] = [state] \n",
    "        \n",
    "        for t in range(1, len(obs)): \n",
    "            V.append({})\n",
    "            newpath = {}\n",
    "            \n",
    "            for cur_state in states: \n",
    "                step_score = []\n",
    "                for prev_state in states:\n",
    "                    score = (\n",
    "                        V[t - 1][prev_state] * \n",
    "                        mask_get(trans_p, prev_state, cur_state) * \n",
    "                        mask_get(emit_p, cur_state, obs[t])\n",
    "                    )\n",
    "                    step_score.append((score, prev_state))\n",
    "                max_score, max_state = max(step_score)\n",
    "                V[t][cur_state] = max_score\n",
    "                newpath[cur_state] = path[max_state] + [cur_state]\n",
    "            path = newpath\n",
    "        (prob, state) = max((V[len(obs) - 1][y], y) for y in states)\n",
    "        # Because our predictions are reliant on the t-1 element, we only hijack for conditional checks here\n",
    "        preds = path[state]\n",
    "        for t in range(len(obs)):\n",
    "            word = obs[t]\n",
    "            if \"@user_\" in word:\n",
    "                preds[t] = \"@\"\n",
    "            elif \"http://\" in word:\n",
    "                preds[t] = \"U\"\n",
    "            elif \"#\" == word[0]: # Check if hashtag at start of word\n",
    "                preds[t] = \"#\"\n",
    "            elif word in filtered_d:\n",
    "                preds[t] = filtered_d[word]\n",
    "        return (prob, preds)\n",
    "    \n",
    "    with open(out_predictions_filename, \"w\") as f:\n",
    "        for post in posts: \n",
    "            prob, paths = single_post_viterbi(post, states, transition_probabilties, output_probabilities)\n",
    "            for state in paths:\n",
    "                f.write(f\"{state}\\n\")  \n",
    "            f.write(f\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "300e9b62-8dbb-4585-8d8e-b75d673c01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi_predict2(\n",
    "    in_tags_filename, \n",
    "    trans_probs_filename2, \n",
    "    output_probs_filename2, \n",
    "    in_test_filename, \n",
    "    viterbi_predictions_filename2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183e754-cc42-4b44-b17e-c643490705f4",
   "metadata": {},
   "source": [
    "### 4(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d3919562-2dbe-4b2d-bf3b-adb647178688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1135, 1378, 0.8236574746008708)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    viterbi_predictions_filename2, \n",
    "    in_ans_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da3506-2051-4b99-b02c-f4ad8ca8f03a",
   "metadata": {},
   "source": [
    "### Checks - How can we further improve Viterbi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8351dba5-450c-4cf2-8c77-5e03212f11b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1477 1477 1477\n"
     ]
    }
   ],
   "source": [
    "with (\n",
    "    open(viterbi_predictions_filename2, \"r\") as f, \n",
    "    open(in_ans_filename, \"r\") as fa,\n",
    "    open(in_test_filename, \"r\") as ft\n",
    "):\n",
    "    preds = [line.strip(\"\\n\") for line in f]\n",
    "    ans = [line.strip(\"\\n\") for line in fa]\n",
    "    word = [line.strip().split(\"\\t\")[0] for line in ft]\n",
    "    print(len(preds), len(ans), len(word))\n",
    "    \n",
    "df = pd.DataFrame([preds, ans, word]).T\n",
    "df.columns = ['preds', 'ans', 'word']\n",
    "\n",
    "df[(df.preds != df.ans) & (df.preds.str.strip() != '')].to_csv(\"ts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
